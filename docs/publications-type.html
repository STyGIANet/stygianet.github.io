<!DOCTYPE html>
<html lang="en" data-bs-theme="auto">
<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  <meta name="keywords" content="STyGIANet, vamsiaddanki,vamsi addanki,vamsi,addanki,venkata,lalitha,sesha,sai,VLSS,collective communication, HPC, datacenter, data center, networking, photonics,tcp,online,topologies,reconfigurable,communication,technology,phd,doctoral,student,researcher,computer,science,papers,publications,algorithms,networks,networking">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Publications (By type) | STyGIANet</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Publications (By type)" />
<meta name="author" content="Vamsi Addanki" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="STyGIANet" />
<meta property="og:description" content="STyGIANet" />
<link rel="canonical" href="https://www.vamsiaddanki.net/publications-type.html" />
<meta property="og:url" content="https://www.vamsiaddanki.net/publications-type.html" />
<meta property="og:site_name" content="STyGIANet" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Publications (By type)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Vamsi Addanki"},"description":"STyGIANet","headline":"Publications (By type)","url":"https://www.vamsiaddanki.net/publications-type.html"}</script>
<!-- End Jekyll SEO tag -->


  <title>Publications (By type) | STyGIANet</title>

  <link href="/dist/css/bootswatch-lux.css" rel="stylesheet">
  <link href="/dist/css/custom.css" rel="stylesheet">
  <!-- Bootstrap Icons CDN -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css">

  <style>
    .navbar-brand,
    .navbar .nav-link {
      text-transform: none !important;
      letter-spacing: normal !important; /* some themes also add spacing */
    }
    body { padding-top: 70px; }
  </style>
   

</head>


<body>

  <nav id="mainNavbar" class="navbar navbar-expand-lg bg-info sticky-nav" data-bs-theme="dark">
  <div class="container" style="max-width: 1080px;">
    <a href="https://purdue.edu">
      <img src="/images/purdue-logo.png" alt="STyGIANet logo" height="25"
           class="d-inline-block align-middle me-5">
    </a>
    <a class="navbar-brand me-5" href="/">Home</a>
    <button class="navbar-toggler collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02"
            aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
      <span class="toggler-icon top-bar"></span>
      <span class="toggler-icon middle-bar"></span>
      <span class="toggler-icon bottom-bar"></span>
    </button>
    <div class="collapse navbar-collapse collapse navbar-collapse mt-3 mt-lg-0" id="navbarColor02">
      <ul class="navbar-nav me-auto">
        
          
          <li class="nav-item"><a class="nav-link" href="/people">People</a></li>
          
          
        
          
          
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button"
               aria-haspopup="true" aria-expanded="false">Publications</a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/publications-all">All</a>
                <div class="dropdown-divider"></div>
              
                <a class="dropdown-item" href="/publications-date">By date</a>
                
              
                <a class="dropdown-item" href="/publications-type">By type</a>
                
              
          </li>
          
        
          
          <li class="nav-item"><a class="nav-link" href="/courses/courses-index">Courses</a></li>
          
          
        
          
          <li class="nav-item"><a class="nav-link" href="/service">Service</a></li>
          
          
        
          
          
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button"
               aria-haspopup="true" aria-expanded="false">Projects</a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/projects-overview">Overview</a>
                <div class="dropdown-divider"></div>
              
                <a class="dropdown-item" href="#">Congestion Control</a>
                
              
                <a class="dropdown-item" href="#">Reconfigurable Networks</a>
                
              
                <a class="dropdown-item" href="#">Online Algorithms</a>
                
              
                <a class="dropdown-item" href="#">Buffer Management</a>
                
              
          </li>
          
        
          
          
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button"
               aria-haspopup="true" aria-expanded="false">Personal</a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/favmusic">Favourite music</a>
                
              
          </li>
          
        
      </ul>
      <!-- Theme toggle with icon -->
      <button id="themeToggle" class="btn btn-outline-dark btn-sm ms-3">
        <i id="themeIcon" class="bi bi-sun-fill"></i>
      </button>
    </div>
  </div>
</nav>
<br>
  
  <div class="container" style="max-width: 1200px; text-align: justify; hyphens: auto;" >
    <h1 id="publications">Publications</h1>

<p>Grouped by type: <a href="publications-type">here</a> ; Grouped by date: <a href="publications-date">here</a>; All: <a href="publications-all">here</a></p>

<h2 id="conference-or-workshop-proceedings">Conference or Workshop Proceedings</h2>
<ol class="bibliography" reversed="reversed"><li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">NSDI ’25</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Pyrrha: Congestion-Root-Based Flow Control to Eliminate Head-of-Line Blocking in Datacenter</strong><br />

    
      <span id="pyrrha25">Kexin Liu, Zhaochen Zhang, Chang Liu, Yizhi Wang, Vamsi Addanki, Stefan Schmid, Qingyue Wang, Wei Chen, Xiaoliang Wang, Jiaqi Zheng, Wenhao Sun, Tao Wu, Ke Meng, Fei Chen, Weiguang Wang, Bingyang Liu, Wanchun Dou, Guihai Chen, and Chen Tian.</span><br />
    

    

    

    
      
        22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25),
      
      
        Philadelphia, PA,
      
      
        2025.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/pyrrha-nsdi2025.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractpyrrha25"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexpyrrha25"> BibTeX</a>

      <div class="collapse" id="abstractpyrrha25">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractpyrrha25">here</a> to close the dropdown!
        </div>
         In modern datacenters, the effectiveness of end-to-end congestion control (CC) is quickly diminishing with the rapid bandwidth evolution. Per-hop flow control (FC) can react to congestion more promptly. However, a coarse-grained FC can result in Head-Of-Line (HOL) blocking. A fine-grained, per-flow FC can eliminate HOL blocking caused by flow control, however, it does not scale well. This paper presents Pyrrha, a scalable flow control approach that provably eliminates HOL blocking while using a minimum number of queues. In Pyrrha, flow control first takes effect on the root of the congestion, i.e., the port where congestion occurs. And then flows are controlled according to their contributed congestion roots. A prototype of Pyrrha is implemented on Tofino2 switches. Compared with state-of-the-art approaches, the average FCT of uncongested flows is reduced by 42%-98%, and 99th-tail latency can be 1.6×-215× lower, without compromising the performance of congested flows. 
      </div>

      <div class="collapse" id="bibtexpyrrha25">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexpyrrha25">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{pyrrha25,
  author = {Liu, Kexin and Zhang, Zhaochen and Liu, Chang and Wang, Yizhi and Addanki, Vamsi and Schmid, Stefan and Wang, Qingyue and Chen, Wei and Wang, Xiaoliang and Zheng, Jiaqi and Sun, Wenhao and Wu, Tao and Meng, Ke and Chen, Fei and Wang, Weiguang and Liu, Bingyang and Dou, Wanchun and Chen, Guihai and Tian, Chen},
  title = {Pyrrha: Congestion-Root-Based Flow Control to Eliminate Head-of-Line Blocking in Datacenter},
  booktitle = {22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25)},
  year = {2025},
  address = {Philadelphia, PA},
  publisher = {USENIX Association}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">LEO-NET ’24</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Starlink Performance through the Edge Router Lens</strong><br />

    
      <span id="starlinkleonet24">Sarah-Michelle Hammer, Vamsi Addanki, Max Franke, and Stefan Schmid.</span><br />
    

    

    

    
      
        Proceedings of the 2nd ACM Workshop on LEO Networking and Communication 2024,
      
      
        Washington, DC., USA,
      
      
        2024.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/starlink-leonet2024.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractstarlinkleonet24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexstarlinkleonet24"> BibTeX</a>

      <div class="collapse" id="abstractstarlinkleonet24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractstarlinkleonet24">here</a> to close the dropdown!
        </div>
         Low-Earth Orbit satellite-based Internet has become commercially available to end users, with Starlink being the most prominent provider. Starlink has been shown to exhibit a periodic pattern with a characteristic throughput drop on the boundaries of 15s intervals, in addition to multiple bands of latency within each 15s interval. A multitude of prior works hypothesize various root causes for this pattern, such as reordering and packet loss. Some works have attributed these effects to the edge router, advocating for explicit feedback to the transport layer. However, with the edge router being a proprietary Starlink device, it raises questions about the extent of its influence on periodic throughput drops, losses, and jitter, leaving us to wonder if we fully understand the underlying issues. <br /> &nbsp;&nbsp;&nbsp;&nbsp; This paper presents the first measurement study with a vantage point that is by far the closest (last hop) to the core Starlink network. We use a Generation 1 dish, which allows us to bypass the proprietary Starlink router and connect a Linux server directly to the dish. We investigate the impact of the edge router on the observed periodic pattern in Starlink performance. Our results are primarily negative in terms of any significant buffer buildup and packet losses at the edge router, suggesting that the causality of the observed patterns lies entirely in the core network, a proprietary space that cannot be fixed by the end user. Interestingly, we observe similar patterns even with a constant bitrate UDP sender, likely indicating that the periodic drop in throughput is not an inherent limitation of existing TCP implementations but rather the core network characteristic! 
      </div>

      <div class="collapse" id="bibtexstarlinkleonet24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexstarlinkleonet24">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{starlinkleonet24,
  author = {Hammer, Sarah-Michelle and Addanki, Vamsi and Franke, Max and Schmid, Stefan},
  title = {Starlink Performance through the Edge Router Lens},
  booktitle = {Proceedings of the 2nd ACM Workshop on LEO Networking and Communication 2024},
  year = {2024},
  address = {Washington, DC., USA}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">NSDI ’24</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Credence: Augmenting Datacenter Switch Buffer Sharing with ML Predictions</strong><br />

    
      <span id="credencensdi24">Vamsi Addanki, Maciej Pacut, and Stefan Schmid.</span><br />
    

    

    

    
      
        21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24),
      
      
        Santa Clara, CA,
      
      
        2024.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/credence-nsdi2024.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/credence-slides-nsdi2024.pdf"> Slides</a>&nbsp;
    

    

    
      <i class="bi bi-camera-reels"></i><a href="https://www.youtube.com/watch?v=sAPe78RFsz0"> Video</a>&nbsp;
    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/inet-tub/ns3-datacenter"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractcredencensdi24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexcredencensdi24"> BibTeX</a>

      <div class="collapse" id="abstractcredencensdi24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractcredencensdi24">here</a> to close the dropdown!
        </div>
        Packet buffers in datacenter switches are shared across all the switch ports in order to improve the overall throughput. The trend of shrinking buffer sizes in datacenter switches makes buffer sharing extremely challenging and a critical performance issue. Literature suggests that push-out buffer sharing algorithms have significantly better performance guarantees compared to drop-tail algorithms. Unfortunately, switches are unable to benefit from these algorithms due to lack of support for push-out operations in hardware. Our key observation is that drop-tail buffers can emulate push-out buffers if the future packet arrivals are known ahead of time. Recent advancements in traffic predictions pave us a way towards better buffer sharing algorithms that leverage predictions. <br /> &nbsp;&nbsp;&nbsp;&nbsp; This paper is the first research attempt in this direction. We propose Credence, a drop-tail buffer sharing algorithm augmented with machine-learned predictions. Credence can unlock the performance only attainable by push-out algorithms so far. Its performance hinges on the accuracy of predictions. Specifically, Credence achieves near-optimal performance of the best known push-out algorithm LQD (Longest Queue Drop) with perfect predictions, but gracefully degrades to the performance of the simplest drop-tail algorithm Complete Sharing when the prediction error gets arbitrarily worse. Our evaluations show that Credence improves throughput by 1.5x compared to traditional approaches. In terms of flow completion times, we show that Credence improves upon the state-of-the-art approaches by up to 95% using off-the-shelf machine learning techniques that are also practical in today’s hardware. We believe this work opens several interesting future work opportunities both in systems and theory that we discuss at the end of this paper.
      </div>

      <div class="collapse" id="bibtexcredencensdi24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexcredencensdi24">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{credencensdi24,
  author = {Addanki, Vamsi and Pacut, Maciej and Schmid, Stefan},
  title = {Credence: Augmenting Datacenter Switch Buffer Sharing with ML Predictions},
  booktitle = {21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)},
  year = {2024},
  address = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/nsdi24/presentation/addanki-credence},
  publisher = {USENIX Association}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">NSDI ’24</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Reverie: Low Pass Filter-Based Switch Buffer Sharing for Datacenters with RDMA and TCP Traffic</strong><br />

    
      <span id="reveriensdi24">Vamsi Addanki, Wei Bai, Stefan Schmid, and Maria Apostolaki.</span><br />
    

    

    

    
      
        21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24),
      
      
        Santa Clara, CA,
      
      
        2024.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/reverie-nsdi2024.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/reverie-slides-nsdi2024.pdf"> Slides</a>&nbsp;
    

    

    
      <i class="bi bi-camera-reels"></i><a href="https://www.youtube.com/watch?v=_zUOrdqMAcY"> Video</a>&nbsp;
    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/inet-tub/ns3-datacenter"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractreveriensdi24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexreveriensdi24"> BibTeX</a>

      <div class="collapse" id="abstractreveriensdi24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractreveriensdi24">here</a> to close the dropdown!
        </div>
        The switch buffers in datacenters today are shared by traffic classes with different loss tolerance and reaction to congestion signals. In particular, while legacy applications use loss-tolerant transport, e.g., DCTCP, newer applications require lossless datacenter transport, e.g., RDMA over Converged Ethernet. The allocation of buffers for this diverse traffic mix is managed by a buffer-sharing scheme. Unfortunately, as we analytically show in this paper, the buffer-sharing practices of today’s datacenters pose a fundamental limitation to effectively isolate RDMA and TCP while also maximizing burst absorption. We identify two root causes: (i) the buffer-sharing for RDMA and TCP relies on two independent and often conflicting views of the buffer, namely ingress and egress; and (ii) the buffer-sharing scheme micromanages the buffer and overreacts to the changes in its occupancy during transient congestion. <br /> &nbsp;&nbsp;&nbsp;&nbsp; In this paper, we present Reverie, a buffer-sharing scheme, which, unlike prior works, is suitable for both lossless and loss-tolerant traffic classes, providing isolation as well as superior burst absorption. At the core of Reverie lies a unified (consolidated ingress and egress) admission control that jointly optimizes the buffers for both traffic classes. Reverie, allocates buffer based on a low-pass filter that naturally absorbs bursty queue lengths during transient congestion within the buffer limits. Our evaluation shows that Reverie can improve the performance of RDMA as well as TCP in terms of flow completion times by up to 33%.
      </div>

      <div class="collapse" id="bibtexreveriensdi24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexreveriensdi24">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{reveriensdi24,
  author = {Addanki, Vamsi and Bai, Wei and Schmid, Stefan and Apostolaki, Maria},
  title = {Reverie: Low Pass Filter-Based Switch Buffer Sharing for Datacenters with RDMA and TCP Traffic},
  booktitle = {21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)},
  year = {2024},
  address = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/nsdi24/presentation/addanki-reverie},
  publisher = {USENIX Association}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">eBPF ’23</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>TCP’s Third-Eye: Leveraging eBPF for Telemetry-Powered Congestion Control</strong><br />

    
      <span id="ebpf23">Jörn-Thorben Hinz, Vamsi Addanki, Csaba Györgyi, Theo Jepsen, and Stefan Schmid.</span><br />
    

    

    

    
      
        Proceedings of the 1st Workshop on eBPF and Kernel Extensions, ACM SIGCOMM 2023 Conference,
      
      
        New York, USA,
      
      
        2023.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/tcpthirdeye-ebpf2023.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/tcpthirdeye-slides-ebpf2023.pdf"> Slides</a>&nbsp;
    

    

    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/inet-tub/powertcp-linux"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractebpf23"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexebpf23"> BibTeX</a>

      <div class="collapse" id="abstractebpf23">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractebpf23">here</a> to close the dropdown!
        </div>
         For years, congestion control algorithms have been navigating in the dark, blind to the actual state of the network. They were limited to the course-grained signals that are visible from the OS kernel, which are measured locally (e.g., RTT) or hints of imminent congestion (e.g., packet loss and ECN). As applications and OSs are becoming ever more distributed, it is only natural that the kernel have visibility beyond the host, into the network fabric. Network switches already collect telemetry, but it has been impractical to export it for the end-host to react. <br /> &nbsp;&nbsp;&nbsp;&nbsp; Although some telemetry-based solutions have been proposed, they require changes to the end-host, like custom hardware or new protocols and network stacks. We address the challenges of efficiency and protocol compatibility, showing that it is possible and practical to run telemetry-based congestion control algorithms in the kernel. We design a CCA running in eBPF that can execute different control laws by selecting different types of telemetry. It can be deployed in brownfield environments, without requiring all switches be telemetry-enabled, or kernel recompilation at the end-hosts. When our eBPF program is enabled on hosts without hardware or OS changes, TCP incast workloads experience less queuing (thus lower latency), faster convergence and better fairness. 
      </div>

      <div class="collapse" id="bibtexebpf23">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexebpf23">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{ebpf23,
  author = {Hinz, J\"{o}rn-Thorben and Addanki, Vamsi and Gy\"{o}rgyi, Csaba and Jepsen, Theo and Schmid, Stefan},
  title = {TCP's Third-Eye: Leveraging eBPF for Telemetry-Powered Congestion Control},
  year = {2023},
  booktitle = {Proceedings of the 1st Workshop on eBPF and Kernel Extensions, ACM SIGCOMM 2023 Conference}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">SIGMETRICS ’23</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable Datacenter Networks</strong><br />

    
      <span id="mars23">Vamsi Addanki, Chen Avin, and Stefan Schmid.</span><br />
    

    

    

    
      
        Proc. ACM Meas. Anal. Comput. Syst, ACM SIGMETRICS,
      
      
        Orlando, Florida, USA,
      
      
        2023.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/mars-sigmetrics2023.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/mars-slides-sigmetrics2023.pdf"> Slides</a>&nbsp;
    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractmars23"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexmars23"> BibTeX</a>

      <div class="collapse" id="abstractmars23">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractmars23">here</a> to close the dropdown!
        </div>
         The performance of large-scale computing systems often critically depends on high-performance communication networks. Dynamically reconfigurable topologies, e.g., based on optical circuit switches, are emerging as an innovative new technology to deal with the explosive growth of datacenter traffic. Specifically, periodic reconfigurable datacenter networks (RDCNs) such as RotorNet (SIGCOMM 2017), Opera (NSDI 2020) and Sirius (SIGCOMM 2020) have been shown to provide high throughput, by emulating a complete graph through fast periodic circuit switch scheduling. <br /> &nbsp;&nbsp;&nbsp;&nbsp; However, to achieve such a high throughput, existing reconfigurable network designs pay a high price: in terms of potentially high delays, but also, as we show as a first contribution in this paper, in terms of the high buffer requirements. In particular, we show that under buffer constraints, emulating the high-throughput complete-graph is infeasible at scale, and we uncover a spectrum of unvisited and attractive alternative RDCNs, which emulate regular graphs of lower node degree. <br /> &nbsp;&nbsp;&nbsp;&nbsp; We present Mars, a periodic reconfigurable topology which emulates a d-regular graph with near-optimal throughput. In particular, we systematically analyze how the degree d can be optimized for throughput given the available buffer and delay tolerance of the datacenter. We further show empirically that Mars achieves higher throughput compared to existing systems when buffer sizes are bounded. 
      </div>

      <div class="collapse" id="bibtexmars23">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexmars23">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{mars23,
  author = {Addanki, Vamsi and Avin, Chen and Schmid, Stefan},
  title = {Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable Datacenter Networks},
  year = {2023},
  booktitle = {Proc. ACM Meas. Anal. Comput. Syst, ACM SIGMETRICS},
  url = {https://doi.org/10.1145/3579312}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">INFOCOM ’23</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Self-Adjusting Partially Ordered Lists</strong><br />

    
      <span id="salists">Vamsi Addanki, Maciej Pacut, Arash Pourdamghani, Gábor Rétvári, Stefan Schmid, and Juan Vanerio.</span><br />
    

    

    

    
      
        Proceedings of the IEEE INFOCOM 2023 Conference,
      
      
        New York, USA,
      
      
        2023.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/listaccess-infocom2023.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractsalists"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexsalists"> BibTeX</a>

      <div class="collapse" id="abstractsalists">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractsalists">here</a> to close the dropdown!
        </div>
         We introduce self-adjusting partially ordered lists, a generalization of self-adjusting lists where additionally there may be constraints for the relative order of some nodes in the list. The lists self-adjust to improve performance while serving input sequences exhibiting favorable properties, such as locality of reference, but the constraints must be respected.  <br /> &nbsp;&nbsp;&nbsp;&nbsp; We design a deterministic adjusting algorithm that operates without any assumptions about the input distribution, without maintaining frequency statistics or timestamps. Although the partial order limits the effectiveness of self-adjustments, the deterministic algorithm performs closely to optimum (it is 4-competitive). In addition, we design a family of randomized algorithms with improved competitive ratios, handling also the rearrangement cost scaled by an arbitrary constant d &gt; 1. Moreover, we observe that different constraints influence the competitiveness of online algorithms, and we shed light on this aspect with a lower bound. <br /> &nbsp;&nbsp;&nbsp;&nbsp; We investigate the applicability of our lists in the context of network packet classification. Our evaluations show that our classifier performs similarly to a static list for low-locality traffic, but significantly outperforms Efficuts (by factor 7x), CutSplit (3.6x) and the static list (14x) for high locality and small rulesets. 
      </div>

      <div class="collapse" id="bibtexsalists">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexsalists">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{salists,
  author = {Addanki, Vamsi and Pacut, Maciej and Pourdamghani, Arash and R{\'{e}}tv{\'{a}}ri, G{\'{a}}bor and Schmid, Stefan and Vanerio, Juan},
  title = {Self-Adjusting Partially Ordered Lists},
  year = {2023},
  booktitle = {Proceedings of the IEEE INFOCOM 2023 Conference}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">SIGCOMM ’22</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>ABM: Active Buffer Management in Datacenters</strong><br />

    
      <span id="abm">Vamsi Addanki, Maria Apostolaki, Manya Ghobadi, Stefan Schmid, and Laurent Vanbever.</span><br />
    

    

    

    
      
        Proceedings of the ACM SIGCOMM 2022 Conference,
      
      
        Amsterdam, Netherlands,
      
      
        2022.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/abm-sigcomm2022.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/abm-slides-sigcomm2022.pdf"> Slides</a>&nbsp;
    

    

    
      <i class="bi bi-camera-reels"></i><a href="https://www.youtube.com/watch?v=fYh9pW1eFqc"> Video</a>&nbsp;
    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/inet-tub/ns3-datacenter"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractabm"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexabm"> BibTeX</a>

      <div class="collapse" id="abstractabm">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractabm">here</a> to close the dropdown!
        </div>
        Today’s network devices share buffer across queues to avoid drops during transient congestion and absorb bursts.  As the buffer-per-bandwidth-unit in datacenter decreases, the need for optimal buffer utilization becomes more pressing.  Typical devices use a hierarchical packet admission control scheme: First, a Buffer Management (BM) scheme decides the maximum length per queue at the device level and then an Active Queue Management (AQM) scheme decides which packets will be admitted at the queue level. Unfortunately, the lack of cooperation between the two control schemes leads to (i) harmful interference across queues, due to the lack of isolation; (ii) increased queueing delay, due to the obliviousness to the per-queue drain time; and (iii) thus unpredictable burst tolerance. To overcome these limitations, we propose ABM, Active Buffer Management which incorporates insights from both BM and AQM. Concretely, ABM accounts for both total buffer occupancy (typically used by BM) and queue drain time (typically used by AQM). We analytically prove that ABM provides isolation, bounded buffer drain time and achieves predictable burst tolerance without sacrificing throughput. We empirically find that ABM improves the 99th percentile FCT for short flows by up to 94% compared to the state-of-the-art buffer management. We further show that ABM improves the performance of advanced datacenter transport protocols in terms of FCT by up to 76% compared to DCTCP, TIMELY and PowerTCP under bursty workloads even at moderate load conditions.
      </div>

      <div class="collapse" id="bibtexabm">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexabm">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{abm,
  author = {Addanki, Vamsi and Apostolaki, Maria and Ghobadi, Manya and Schmid, Stefan and Vanbever, Laurent},
  title = {ABM: Active Buffer Management in Datacenters},
  year = {2022},
  booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">NSDI ’22</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>PowerTCP: Pushing the Performance Limits of Datacenter Networks</strong><br />

    
      <span id="nsdi22">Vamsi Addanki, Oliver Michel, and Stefan Schmid.</span><br />
    

    

    

    
      
        19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22),
      
      
        Renton, WA,
      
      
        2022.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/powertcp-nsdi2022.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/powertcp-slides-nsdi2022.pdf"> Slides</a>&nbsp;
    

    

    
      <i class="bi bi-camera-reels"></i><a href="https://www.youtube.com/watch?v=5K7p3jiDeR8"> Video</a>&nbsp;
    

    

    
      <i class="bi bi-globe"></i><a href="https://powertcp.self-adjusting.net"> Website</a>&nbsp;
    

    
      <i class="bi bi-github"></i> <a href="https://github.com/inet-tub/ns3-datacenter"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractnsdi22"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexnsdi22"> BibTeX</a>

      <div class="collapse" id="abstractnsdi22">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractnsdi22">here</a> to close the dropdown!
        </div>
        Increasingly stringent throughput and latency requirements in datacenter networks demand fast and accurate congestion control. We observe that the reaction time and accuracy of existing datacenter congestion control schemes are inherently limited. They either rely only on explicit feedback about the network state (e.g., queue lengths in DCTCP) or only on variations of state (e.g., RTT gradient in TIMELY). To overcome these limitations, we propose a novel congestion control algorithm, PowerTCP, which achieves much more fine-grained congestion control by adapting to the bandwidth-window product (henceforth called power). PowerTCP leverages in-band network telemetry to react to changes in the network instantaneously without loss of throughput and while keeping queues short. Due to its fast reaction time, our algorithm is particularly well-suited for dynamic network environments and bursty traffic patterns. We show analytically and empirically that PowerTCP can significantly outperform the state-of-the-art in both traditional datacenter topologies and emerging reconfigurable datacenters where frequent bandwidth changes make congestion control challenging. In traditional datacenter networks, PowerTCP reduces tail flow completion times of short flows by 80% compared to DCQCN and TIMELY, and by 33% compared to HPCC even at 60% network load. In reconfigurable datacenters, PowerTCP achieves 85% circuit utilization without incurring additional latency and cuts tail latency by at least 2x compared to existing approaches.
      </div>

      <div class="collapse" id="bibtexnsdi22">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexnsdi22">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{nsdi22,
  author = {Addanki, Vamsi and Michel, Oliver and Schmid, Stefan},
  title = {{PowerTCP}: Pushing the Performance Limits of Datacenter Networks},
  booktitle = {19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  year = {2022},
  address = {Renton, WA},
  url = {https://www.usenix.org/conference/nsdi22/presentation/addanki},
  publisher = {USENIX Association}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">Networking ’20</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Moving a step forward in the quest for Deterministic Networks (DetNet)</strong><br />

    
      <span id="detnetnetworking20">Vamsi Addanki and Luigi Iannone.</span><br />
    

    

    

    
      
        2020 IFIP Networking Conference (Networking),
      
      
        Paris, France,
      
      
        2020.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/detnet-networking2020.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/detnet-networking2020-slides.odp"> Slides</a>&nbsp;
    

    

    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/vamsiDT/DeNS"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractdetnetnetworking20"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexdetnetnetworking20"> BibTeX</a>

      <div class="collapse" id="abstractdetnetnetworking20">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractdetnetnetworking20">here</a> to close the dropdown!
        </div>
        Recent years witnessed a fast-growing demand, in the context of industrial use-cases, for the so-called Deterministic Networks (DetNet). IEEE 802.1 TSN architecture provides linklayer services and IETF DetNet provides network-layer services for deterministic and reliable forwarding. In such a context, in the first part of this paper, we tackle the problem of misbehaving flows and propose a novel queuing and scheduling mechanism, based on Push-In-First-Out (PIFO) queues. Differently from the original DetNet/TSN specifications, our solution is able to guarantee performance of priority flows in spite of misbehaving flows. In the second part of this paper, we present our simulator DeNS:DetNet Simulator, based on OMNET++ and NeSTiNG, providing building blocks for link-layer TSN and network-layer DetNet. Existing simulators have important limitations that do not allow simulating the full DetNet/TSN protocol stack. We overcome these limitations, making easy DetNet/TSN evaluations possible. Our simulations clearly show that our solution is able to satisfy constraints of deterministic networks, namely, guarantee zero packet loss and low latency, while at the same time allowing best-effort flows to co-exist. Furthermore, we show how our newly-proposed queuing and scheduling solution successfully limits the impact of misbehaving flows.
      </div>

      <div class="collapse" id="bibtexdetnetnetworking20">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexdetnetnetworking20">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{detnetnetworking20,
  author = {Addanki, Vamsi and Iannone, Luigi},
  booktitle = {2020 IFIP Networking Conference (Networking)},
  title = {Moving a step forward in the quest for Deterministic Networks (DetNet)},
  year = {2020},
  volume = {},
  number = {},
  pages = {458-466},
  doi = {}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">PAM ’20</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Alias Resolution Based on ICMP Rate Limiting</strong><br />

    
      <span id="aliaspam20">Kevin Vermeulen, Burim Ljuma, Vamsi Addanki, Matthieu Gouel, Olivier Fourmaux, Timur Friedman, and Reza Rejaie.</span><br />
    

    

    

    
      
        Passive and Active Measurement,
      
      
      
        2020.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2002.00252.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractaliaspam20"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexaliaspam20"> BibTeX</a>

      <div class="collapse" id="abstractaliaspam20">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractaliaspam20">here</a> to close the dropdown!
        </div>
        Alias resolution techniques (e.g., Midar) associate, mostly through active measurement, a set of IP addresses as belonging to a common router. These techniques rely on distinct router features that can serve as a signature. Their applicability is affected by router support of the features and the robustness of the signature. This paper presents a new alias resolution tool called Limited Ltd. that exploits ICMP rate limiting, a feature that is increasingly supported by modern routers that has not previously been used for alias resolution. It sends ICMP probes toward target interfaces in order to trigger rate limiting, extracting features from the probe reply loss traces. It uses a machine learning classifier to designate pairs of interfaces as aliases. We describe the details of the algorithm used by Limited Ltd. and illustrate its feasibility and accuracy. Limited Ltd. not only is the first tool that can perform alias resolution on IPv6 routers that do not generate monotonically increasing fragmentation IDs (e.g., Juniper routers) but it also complements the state-of-the-art techniques for IPv4 alias resolution. All of our code and the collected dataset are publicly available.
      </div>

      <div class="collapse" id="bibtexaliaspam20">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexaliaspam20">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{aliaspam20,
  author = {Vermeulen, Kevin and Ljuma, Burim and Addanki, Vamsi and Gouel, Matthieu and Fourmaux, Olivier and Friedman, Timur and Rejaie, Reza},
  editor = {Sperotto, Anna and Dainotti, Alberto and Stiller, Burkhard},
  title = {Alias Resolution Based on ICMP Rate Limiting},
  booktitle = {Passive and Active Measurement},
  year = {2020},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {231--248},
  isbn = {978-3-030-44081-7}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">Networking ’18</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Controlling software router resource sharing by fair packet dropping</strong><br />

    
      <span id="fairdropnetworking18">Vamsi Addanki, Leonardo Linguaglossa, James Roberts, and Dario Rossi.</span><br />
    

    

    

    
      
        IFIP Networking Conference (IFIP Networking) and Workshops,
      
      
        Zurich, Switzerland,
      
      
        2018.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/fairdrop-networking2018.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    
      <i class="bi bi-github"></i> <a href="https://github.com/vamsiDT/fairdrop-results"> Code</a>&nbsp;
    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractfairdropnetworking18"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexfairdropnetworking18"> BibTeX</a>

      <div class="collapse" id="abstractfairdropnetworking18">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractfairdropnetworking18">here</a> to close the dropdown!
        </div>
        The paper discusses resource sharing in a software router where both bandwidth and CPU may be bottlenecks. We propose a novel fair dropping algorithm to realize per-flow max-min fair sharing of these resources. The algorithm is compatible with features like batch I/O and batch processing that tend to make classical scheduling impractical. We describe an implementation using Vector Packet Processing, part of the Linux Foundation FD.io project. Preliminary experimental results prove the efficiency of the algorithm in controlling bandwidth and CPU sharing at high speed. Performance in dynamic traffic is evaluated using analysis and simulation, demonstrating that the proposed approach is both effective and scalable.
      </div>

      <div class="collapse" id="bibtexfairdropnetworking18">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexfairdropnetworking18">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{fairdropnetworking18,
  author = {Addanki, Vamsi and Linguaglossa, Leonardo and Roberts, James and Rossi, Dario},
  booktitle = {IFIP Networking Conference (IFIP Networking) and Workshops},
  title = {Controlling software router resource sharing by fair packet dropping},
  year = {2018},
  volume = {},
  number = {},
  pages = {1-9},
  doi = {10.23919/IFIPNetworking.2018.8696549}
}
</pre>
      </div>
    
  </div>
</div>
</li></ol>

<h2 id="tech-reports">Tech Reports</h2>
<ol class="bibliography" reversed="reversed"><li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    
      <span class="badge bg-secondary rounded-pill">arXiv</span><br />
    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Ethereal: Divide and Conquer Network Load Balancing in Large-Scale Distributed Training</strong><br />

    
      <span id="ethereal24">Vamsi Addanki, Prateesh Goyal, Ilias Marinos, and Stefan Schmid.</span><br />
    

    

    
      
        CoRR,
      
      
      
        2025.
      
    

    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2407.00550"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractethereal24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexethereal24"> BibTeX</a>

      <div class="collapse" id="abstractethereal24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractethereal24">here</a> to close the dropdown!
        </div>
         Large-scale distributed training in production datacenters constitutes a challenging workload bottlenecked by network communication. In response, both major industry players (e.g., Ultra Ethernet Consortium) and parts of academia have surprisingly, and almost unanimously, agreed that packet spraying is <i>necessary</i> to improve the performance of large-scale distributed training workloads. <br /> &nbsp;&nbsp;&nbsp;&nbsp; In this paper, we challenge this prevailing belief and pose the question: <i>How close can singlepath transport come to matching the performance of packet spraying?</i> We demonstrate that singlepath transport (from a NIC’s perspective) is sufficient and can perform nearly as well as ideal packet spraying, particularly in the context of distributed training in CLOS-based topologies. Our assertion is based on four key observations about workloads driven by collective communication patterns: <i>(i)</i> flow sizes are known upon arrival, <i>(ii)</i> flow sizes are equal within each step of a collective, <i>(iii)</i> the completion time of a collective is more critical than individual flow completion times, and <i>(iv)</i> flows can be <i>split</i> upon arrival to control load balancing directly from the application layer.   <br /> &nbsp;&nbsp;&nbsp;&nbsp; We present Ethereal, a simple distributed load balancing algorithm that opportunistically splits flows and assigns paths to each flow in a transparent manner, requiring little to no changes to existing RDMA NICs. Our evaluation, spanning a wide range of collective communication algorithms and GPT models using Astra-Sim, shows that Ethereal significantly reduces the completion times by up to 30% compared to packet spraying and by up to 40% compared to REPS, even under link failures. This paper offers an alternative perspective for developing next-generation transport protocols tailored to large-scale distributed training. 
      </div>

      <div class="collapse" id="bibtexethereal24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexethereal24">here</a> to close the dropdown!
        </div>
        <pre>@article{ethereal24,
  author = {Addanki, Vamsi and Goyal, Prateesh and Marinos, Ilias and Schmid, Stefan},
  url = {https://arxiv.org/abs/2407.00550},
  title = {Ethereal: Divide and Conquer Network Load Balancing in Large-Scale Distributed Training},
  journal = {CoRR},
  volume = {abs/2407.00550},
  year = {2025},
  eprinttype = {arXiv},
  eprint = {2407.00550}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    
      <span class="badge bg-secondary rounded-pill">arXiv</span><br />
    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Understanding the Throughput Bounds of Reconfigurable Datacenter Networks</strong><br />

    
      <span id="demandawarethroughput24">Vamsi Addanki, Chen Avin, and Stefan Schmid.</span><br />
    

    

    
      
        CoRR,
      
      
      
        2024.
      
    

    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2405.20869"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractdemandawarethroughput24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexdemandawarethroughput24"> BibTeX</a>

      <div class="collapse" id="abstractdemandawarethroughput24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractdemandawarethroughput24">here</a> to close the dropdown!
        </div>
         The increasing gap between the growth of datacenter traffic volume and the capacity of electrical switches led to the emergence of reconfigurable datacenter network designs based on optical circuit switching. A multitude of research works, ranging from demand-oblivious (e.g., RotorNet, Sirius) to demand-aware (e.g., Helios, ProjecToR) reconfigurable networks, demonstrate significant performance benefits. Unfortunately, little is formally known about the achievable throughput of such networks. Only recently have the throughput bounds of demand-oblivious networks been studied. In this paper, we tackle a fundamental question: Whether and to what extent can demand-aware reconfigurable networks improve the throughput of datacenters? <br /> &nbsp;&nbsp;&nbsp;&nbsp; This paper attempts to understand the landscape of the throughput bounds of reconfigurable datacenter networks. Given the rise of machine learning workloads and collective communication in modern datacenters, we specifically focus on their typical communication patterns, namely uniform-residual demand matrices. We formally establish a separation bound of demand-aware networks over demand-oblivious networks, proving analytically that the former can provide at least 16% higher throughput. Our analysis further uncovers new design opportunities based on periodic, fixed-duration reconfigurations that can harness the throughput benefits of demand-aware networks while inheriting the simplicity and low reconfiguration overheads of demand-oblivious networks. Finally, our evaluations corroborate the theoretical results of this paper, demonstrating that demand-aware networks significantly outperform oblivious networks in terms of throughput. This work barely scratches the surface and unveils several intriguing open questions, which we discuss at the end of this paper. 
      </div>

      <div class="collapse" id="bibtexdemandawarethroughput24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexdemandawarethroughput24">here</a> to close the dropdown!
        </div>
        <pre>@article{demandawarethroughput24,
  author = {Addanki, Vamsi and Avin, Chen and Schmid, Stefan},
  url = {https://arxiv.org/abs/2405.20869},
  title = {Understanding the Throughput Bounds of Reconfigurable Datacenter Networks},
  journal = {CoRR},
  volume = {abs/2405.20869},
  year = {2024},
  eprinttype = {arXiv},
  eprint = {2405.20869}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    
      <span class="badge bg-secondary rounded-pill">arXiv</span><br />
    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>FB: A Flexible Buffer Management Scheme for Data Center Switches</strong><br />

    
      <span id="bufferfbreview21">Maria Apostolaki, Vamsi Addanki, Manya Ghobadi, and Laurent Vanbever.</span><br />
    

    

    
      
        CoRR,
      
      
      
        2021.
      
    

    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2105.10553.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractbufferfbreview21"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexbufferfbreview21"> BibTeX</a>

      <div class="collapse" id="abstractbufferfbreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractbufferfbreview21">here</a> to close the dropdown!
        </div>
         Today, network devices share buffer across priority queues to avoid drops during transient congestion. While cost-effective most of the time, this sharing can cause undesired interference among seemingly independent traffic. As a result, low-priority traffic can cause increased packet loss to high-priority traffic. Similarly, long flows can prevent the buffer from absorbing incoming bursts even if they do not share the same queue. The cause of this perhaps unintuitive outcome is that today’s buffer sharing techniques are unable to guarantee isolation across (priority) queues without statically allocating buffer space. To address this issue, we designed FB, a novel buffer sharing scheme that offers strict isolation guarantees to high-priority traffic without sacrificing link utilizations. Thus, FB outperforms conventional buffer sharing algorithms in absorbing bursts while achieving on-par throughput. We show that FB is practical and runs at line-rate on existing hardware (Barefoot Tofino). Significantly, FB’s operations can be approximated in non-programmable devices. 
      </div>

      <div class="collapse" id="bibtexbufferfbreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexbufferfbreview21">here</a> to close the dropdown!
        </div>
        <pre>@article{bufferfbreview21,
  author = {Apostolaki, Maria and Addanki, Vamsi and Ghobadi, Manya and Vanbever, Laurent},
  url = {https://arxiv.org/abs/2105.10553},
  title = {{FB:} {A} Flexible Buffer Management Scheme for Data Center Switches},
  journal = {CoRR},
  volume = {abs/2105.10553},
  year = {2021},
  eprinttype = {arXiv},
  eprint = {2105.10553}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    
      <span class="badge bg-secondary rounded-pill">arXiv</span><br />
    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Self-Adjusting Packet Classification</strong><br />

    
      <span id="firewallreview21">Maciej Pacut, Juan Vanerio, Vamsi Addanki, Arash Pourdamghani, Gábor Rétvári, and Stefan Schmid.</span><br />
    

    

    
      
        CoRR,
      
      
      
        2021.
      
    

    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2109.15090.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractfirewallreview21"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexfirewallreview21"> BibTeX</a>

      <div class="collapse" id="abstractfirewallreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractfirewallreview21">here</a> to close the dropdown!
        </div>
         This paper is motivated by the vision of more efficient packet classification mechanisms that self-optimize in a demand-aware manner. At the heart of our approach lies a self-adjusting linear list data structure, where unlike in the classic data structure, there are dependencies, and some items must be in front of the others; for example, to correctly classify packets by rules arranged in a linked list, each rule must be in front of lower priority rules that overlap with it. After each access we can rearrange the list, similarly to Move-To-Front, but dependencies need to be respected. <br /> &nbsp;&nbsp;&nbsp;&nbsp; We present a 4-competitive online rearrangement algorithm, whose cost is at most four times worse than the optimal offline algorithm; no deterministic algorithm can be better than 3-competitive. The algorithm is simple and attractive, especially for memory-limited systems, as it does not require any additional memory (e.g., neither timestamps nor frequency statistics). Our approach can simply be deployed as a drop-in replacement for a static datastructure, potentially benefitting many existing networks. <br /> &nbsp;&nbsp;&nbsp;&nbsp; We evaluate our self-adjusting list packet classifier on realistic ruleset and traffic instances. We find that our classifier performs similarly to a static list for low-locality traffic, but significantly outperforms Efficuts (by a factor 7x), CutSplit (3.6x), and the static list (14x) for high locality and small rulesets. Memory consumption is 10x lower on average compared to Efficuts and CutSplit. 
      </div>

      <div class="collapse" id="bibtexfirewallreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexfirewallreview21">here</a> to close the dropdown!
        </div>
        <pre>@article{firewallreview21,
  author = {Pacut, Maciej and Vanerio, Juan and Addanki, Vamsi and Pourdamghani, Arash and R{\'{e}}tv{\'{a}}ri, G{\'{a}}bor and Schmid, Stefan},
  title = {Self-Adjusting Packet Classification},
  journal = {CoRR},
  volume = {abs/2109.15090},
  year = {2021},
  url = {https://arxiv.org/abs/2109.15090},
  eprinttype = {arXiv},
  eprint = {2109.15090}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    
      <span class="badge bg-secondary rounded-pill">arXiv</span><br />
    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Online List Access with Precedence Constraints</strong><br />

    
      <span id="listaccessreview21">Maciej Pacut, Juan Vanerio, Vamsi Addanki, Arash Pourdamghani, Gábor Rétvári, and Stefan Schmid.</span><br />
    

    

    
      
        CoRR,
      
      
      
        2021.
      
    

    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="https://arxiv.org/pdf/2104.08949.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractlistaccessreview21"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexlistaccessreview21"> BibTeX</a>

      <div class="collapse" id="abstractlistaccessreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractlistaccessreview21">here</a> to close the dropdown!
        </div>
         This paper considers a natural generalization of the online list access problem in the paid exchange model, where additionally there can be precedence constraints ("dependencies") among the nodes in the list. For example, this generalization is motivated by applications in the context of packet classification. Our main contributions are constant-competitive deterministic and randomized online algorithms, designed around a procedure Move-Recursively-Forward, a generalization of Move-To-Front tailored to handle node dependencies. Parts of the analysis build upon ideas of the classic online algorithms Move-To-Front and BIT, and address the challenges of the extended model. We further discuss the challenges related to insertions and deletions. 
      </div>

      <div class="collapse" id="bibtexlistaccessreview21">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexlistaccessreview21">here</a> to close the dropdown!
        </div>
        <pre>@article{listaccessreview21,
  author = {Pacut, Maciej and Vanerio, Juan and Addanki, Vamsi and Pourdamghani, Arash and R{\'{e}}tv{\'{a}}ri, G{\'{a}}bor and Schmid, Stefan},
  title = {Online List Access with Precedence Constraints},
  journal = {CoRR},
  volume = {abs/2104.08949},
  year = {2021},
  url = {https://arxiv.org/abs/2104.08949},
  eprinttype = {arXiv},
  eprint = {2104.08949}
}
</pre>
      </div>
    
  </div>
</div>
</li></ol>

<h2 id="posters-or-demos">Posters or Demos</h2>
<ol class="bibliography" reversed="reversed"><li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">CoNEXT-SW ’24</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Dequeue Rate-Agnostic Switch Buffer Sharing through Packet Queueing Delay</strong><br />

    
      <span id="cbmconextsw24">Krishna Agarwal, Vamsi Addanki, and Habib Mostafaei.</span><br />
    

    

    

    
      
        Proceedings of the CoNEXT Student Workshop 2024 (CoNEXT-SW ’24),
      
      
        Los Angeles, CA, USA,
      
      
        2024.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/cbm-conextSW2024.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractcbmconextsw24"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexcbmconextsw24"> BibTeX</a>

      <div class="collapse" id="abstractcbmconextsw24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractcbmconextsw24">here</a> to close the dropdown!
        </div>
        Datacenter network switches share packet buffers among all ports to enhance throughput and reduce packet drops. However, declining buffer space per-port-per-bandwidth unit challenges buffer-sharing mechanisms, affecting performance. Recent studies, like ABM (SIGCOMM 2022), suggest hierarchical packet admission schemes to address this, but their complexity hinders efficiency. We propose CBM, a packet delay-based buffer sharing scheme that manages buffer space and controls queue drain rates using a single configurable parameter. Preliminary evaluation shows that CBM improves advanced transport protocol performance, such as PowerTCP, reducing Flow Completion Times (FCTs) by up to 45.07% compared with ABM.
      </div>

      <div class="collapse" id="bibtexcbmconextsw24">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexcbmconextsw24">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{cbmconextsw24,
  author = {Agarwal, Krishna and Addanki, Vamsi and Mostafaei, Habib},
  title = {Dequeue Rate-Agnostic Switch Buffer Sharing through Packet Queueing Delay},
  year = {2024},
  isbn = {979-8-4007-1255-5/24/1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3694812.3699924},
  doi = {10.1145/3694812.3699924},
  booktitle = {Proceedings of the CoNEXT Student Workshop 2024 (CoNEXT-SW ’24)},
  numpages = {2},
  keywords = {Switch buffer, packet queueing delay, datacenter networks},
  series = {CoNEXT-SW '24}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    
      <span class="badge bg-primary rounded-pill">SIGCOMM ’18</span><br />
    

    

    

    

    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Fair Dropping for Multi-Resource Fairness in Software Routers Extended Abstract</strong><br />

    
      <span id="fairdropsigcomm18">Vamsi Addanki, Leonardo Linguaglossa, James Roberts, and Dario Rossi.</span><br />
    

    

    

    
      
        Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos,
      
      
        Budapest, Hungary,
      
      
        2018.
      
    

    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/fairdrop-demo-sigcomm2018.pdf"> PDF</a>&nbsp;
    

    

    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/posters/fairdrop-poster-sigcomm2018.pdf"> Poster</a>&nbsp;
    

    
      <i class="bi bi-camera-reels"></i><a href="/videos/fairdrop-bw-demo.mp4"> Video</a>&nbsp;
    

    
      <i class="bi bi-camera-reels"></i> <a href="/videos/fairdrop-cpu-demo.mp4">Video-contd.</a>&nbsp;
    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractfairdropsigcomm18"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexfairdropsigcomm18"> BibTeX</a>

      <div class="collapse" id="abstractfairdropsigcomm18">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractfairdropsigcomm18">here</a> to close the dropdown!
        </div>
        We demonstrate that fair dropping is an effective means to realize fair sharing of bandwidth and CPU in a software router. Analysis underpinning the effectiveness of the proposed approach is presented elsewhere [1].
      </div>

      <div class="collapse" id="bibtexfairdropsigcomm18">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexfairdropsigcomm18">here</a> to close the dropdown!
        </div>
        <pre>@inproceedings{fairdropsigcomm18,
  author = {Addanki, Vamsi and Linguaglossa, Leonardo and Roberts, James and Rossi, Dario},
  title = {Fair Dropping for Multi-Resource Fairness in Software Routers Extended Abstract},
  year = {2018},
  isbn = {9781450359153},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3234200.3234210},
  doi = {10.1145/3234200.3234210},
  booktitle = {Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos},
  pages = {132–134},
  numpages = {3},
  keywords = {vector packet processing (VPP), fair dropping, multi-resource fairness, Linux Foundation FD.io project},
  series = {SIGCOMM '18}
}
</pre>
      </div>
    
  </div>
</div>
</li></ol>

<h2 id="theses">Theses</h2>
<ol class="bibliography" reversed="reversed"><li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    

    
      <span class="badge bg-success rounded-pill" style="color: #000">PhD Thesis</span><br />
    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Adaptive Protocols and Reconfigurable Optical Interconnects for Datacenter Networks</strong><br />

    
      <span id="vamsiphdthesis">Vamsi Addanki.</span><br />
    

    

    

    

    

    
      
        Advisor: Stefan Schmid.<br />
      
      
        Committee: Axel Küpper, Stefan Schmid, Rachit Agarwal, Michael Schapira, Anja Feldmann, Maria Apostolaki.<br />
      
      
        TU Berlin,
      
      
        dec,
      
      
        2024.
      
    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/vamsi-phd-thesis2025.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractvamsiphdthesis"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexvamsiphdthesis"> BibTeX</a>

      <div class="collapse" id="abstractvamsiphdthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractvamsiphdthesis">here</a> to close the dropdown!
        </div>
        Datacenter networks form the backbone of modern computing and storage, driving the expansion of online services and applications. As these networks evolve, the demand for higher bandwidth and lower latency has increased significantly. Recently, GPU clusters have emerged within datacenters for large-scale distributed training, presenting unique networking challenges. <br /> &nbsp;&nbsp;&nbsp;&nbsp; This thesis addresses several critical challenges in datacenter networks—congestion control, load balancing, buffer sharing, and reconfigurable optical interconnects—and is structured into three main parts. <br /> &nbsp;&nbsp;&nbsp;&nbsp; First, we address the transport protocol problem in modern datacenters. We propose PowerTCP, a novel congestion control algorithm that dynamically adjusts the congestion window based on the bandwidth-window product (or “power”), a new congestion indicator. Through both analytical and empirical validation, we demonstrate PowerTCP’s practicality in datacenter networks, showing that it meets key requirements for high throughput and low latency. We further introduce Ethereal, a transport protocol specifically designed for distributed training work- loads in leaf-spine topologies. Ethereal achieves optimal load balancing, akin to packet spraying, by minimally splitting a few application flows while maintaining single-path transport semantics from the network’s perspective. Empirically, we show that Ethereal surpasses state-of-the-art algorithms in collective communica- tion completion times. <br /> &nbsp;&nbsp;&nbsp;&nbsp; Second, we tackle the buffer-sharing problem in datacenter switches. We propose ABM, an innovative buffer-sharing algorithm that ensures isolation across different traffic classes while improving burst absorption. As an extension, we introduce Reverie, a solution that enables lossy and lossless traffic to coexist within the same network. Reverie preserves isolation between these traffic types while enhancing burst absorption and flow completion times for both. Additionally, we propose Credence, the first buffer-sharing algorithm to integrate machine-learned predictions. Our analysis shows that Credence achieves near-optimal throughput under perfect predictions and performs effectively even with imperfect predictions, significantly improving flow completion times in empirical tests. <br /> &nbsp;&nbsp;&nbsp;&nbsp; Finally, as Moore’s law approaches its limits, we address the challenge of high- performance optical interconnects in datacenter networks. We present the first formal result on the throughput of periodic networks, establishing an equivalence to a corresponding static network. Based on this result, we propose Mars, a demand-oblivious reconfigurable optical interconnect that achieves near-optimal throughput and low latency across various traffic patterns, even with shallow buffers. Additionally, we introduce Vermilion, a demand-aware optical interconnect that dynamically reconfigures according to traffic patterns. Our analysis and empirical results show that Vermilion delivers high throughput across diverse traffic patterns, exceeding the throughput capabilities of demand-oblivious interconnects.
      </div>

      <div class="collapse" id="bibtexvamsiphdthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexvamsiphdthesis">here</a> to close the dropdown!
        </div>
        <pre>@dissertation{vamsiphdthesis,
  thesis = {PhD Thesis},
  advisor = {Stefan Schmid},
  committee = {Axel Küpper, Stefan Schmid, Rachit Agarwal, Michael Schapira, Anja Feldmann, Maria Apostolaki},
  title = {Adaptive Protocols and Reconfigurable Optical Interconnects for Datacenter Networks},
  author = {Addanki, Vamsi},
  year = {2024}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    

    
      <span class="badge bg-success rounded-pill" style="color: #000">Masters Thesis</span><br />
    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Plasticine: A flexible buffer management scheme for data center networks</strong><br />

    
      <span id="masterthesis">Vamsi Addanki.</span><br />
    

    

    

    

    
      
        Supervisors: Laurent Vanbever, Maria Apostalaki, Sebastien Tixeuil.<br />
      
      
        ETH Zurich,
      
      
        aug,
      
      
        2020.
      
    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/vamsi-msc-thesis2020.pdf"> PDF</a>&nbsp;
    

    
      <i class="bi bi-file-earmark-slides"></i> <a href="/slides/vamsi-msc-thesis2020-slides.odp"> Slides</a>&nbsp;
    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractmasterthesis"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexmasterthesis"> BibTeX</a>

      <div class="collapse" id="abstractmasterthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractmasterthesis">here</a> to close the dropdown!
        </div>
        Network devices today share buffer across output queues to avoid drops during transient congestion with less buffer space, thus with a lower cost, per chip. While effective most of the time, this sharing can cause undesired interactions among seemingly independent traffic, especially in case of high load. As a result, low-priority traffic can cause increased packet loss to high-priority traffic, intra-DC traffic can impair WAN throughput and long flows can prevent the buffer for absorbing incoming bursts. The cause of this perhaps unintuitive outcome is today’s buffer sharing techniques that are unable to guarantee isolation even to a small portion of the traffic, without statically allocating buffer space. To address this issue we designed Plasticine a novel buffer management scheme which offers strict isolation guarantees without keeping the buffer idle and is practical in today’s hardware. We found that Plasticine: <i>(i)</i> significantly improves query completion times (≈&gt;30% compared to state-of-the-art solution) while achieving on-par throughput compared to convectional buffer management algorithms as well as TCP nuances; <i>(ii)</i> improves short-flow completion times; Our proposal is the first attempt to address the problems of bursts in today’s data center networks from a buffer management perspective.
      </div>

      <div class="collapse" id="bibtexmasterthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexmasterthesis">here</a> to close the dropdown!
        </div>
        <pre>@thesis{masterthesis,
  thesis = {Masters Thesis},
  title = {Plasticine: A flexible buffer management scheme for data center networks},
  author = {Addanki, Vamsi},
  year = {2020}
}
</pre>
      </div>
    
  </div>
</div>
</li>
<li><div class="row mb-4">
  <!-- Left Column: Tags -->
  <div class="col-md-2">
    

    

    

    

    
      <span class="badge bg-success rounded-pill" style="color: #000">Bachelors Thesis</span><br />
    
  </div>

  <!-- Right Column: Main Content -->
  <div class="col-md-10">
    <strong>Vectorized Packet Processing</strong><br />

    
      <span id="bachelorthesis">Vamsi Addanki.</span><br />
    

    

    

    

    
      
        Supervisors: Dario Rossi, Leonardo Linguaglossa.<br />
      
      
        Telecom Paris,
      
      
        jul,
      
      
        2017.
      
    

    

    

    <!-- Media Links -->
    <br />
    
      <i class="bi bi-file-earmark-pdf"></i> <a href="/papers/vamsi-be-thesis2017.pdf"> PDF</a>&nbsp;
    

    

    

    

    

    

    

    <!-- Abstract and BibTeX -->
    
      <i class="bi bi-chat-square-text"></i>
      <a data-bs-toggle="collapse" href="#abstractbachelorthesis"> Abstract</a>&nbsp;
      <i class="bi bi-book"></i>
      <a data-bs-toggle="collapse" href="#bibtexbachelorthesis"> BibTeX</a>

      <div class="collapse" id="abstractbachelorthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#abstractbachelorthesis">here</a> to close the dropdown!
        </div>
        In the last few years, numerous frameworks have emerged which implement network packet processing in user-space using kernel bypass techniques, high-speed software data plane functionalities on commodity hardware. VPP [3] is one such framework which gained popularity recently for some of the interesting points like its flexibility, user-space implementation, kernel bypass techniques etc. VPP allows users to arrange or rearrange the network functions as a packet processing graph, providing a Full-blown stack of network functions. Unlike the other frameworks in which packet processing is done packet-by-packet, VPP performs packet processing, vector-by-vector i.e a batch of packets at once. This brings a significant performance benefits due to L1 cache hit. In this report I discuss an introduction to Vector Packet Processor, a framework by Cisco which is now a part of the Fast Data Input Output (FD.io) project [2]. Later in this report I will discuss about the initial experiments on VPP, the test bed used for performing the experiments with VPP and how to set up the test bed. The variation of three values (Throughput, Average Vector size, CPU clock cycles) are observed while changing Maximum vector size. The result clearly show that cache-hit ratio increases from vector size of 4 to 256 where it is maximum and decreases.I begin with related work about packet processing to understand why VPP is important in the high speed networking world.
      </div>

      <div class="collapse" id="bibtexbachelorthesis">
        <div class="alert alert-dismissible alert-secondary">
          <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
          Click <a data-bs-toggle="collapse" href="#bibtexbachelorthesis">here</a> to close the dropdown!
        </div>
        <pre>@thesis{bachelorthesis,
  thesis = {Bachelors Thesis},
  title = {Vectorized Packet Processing},
  author = {Addanki, Vamsi},
  year = {2017}
}
</pre>
      </div>
    
  </div>
</div>
</li></ol>

  </div>

  <!--  -->
<!--  -->
<!--  -->

<script src="/dist/js/jquery.js"></script>
<script src="/dist/js/bootstrap.bundle.js"></script>

<script>
var popoverTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="popover"]'))
var popoverList = popoverTriggerList.map(function (popoverTriggerEl) {
  return new bootstrap.Popover(popoverTriggerEl)
})
</script>

<script>
  function toggleDropdown (e) {
  const _d = $(e.target).closest('.dropdown'),
    _m = $('.dropdown-menu', _d);
  setTimeout(function(){
    const shouldOpen = e.type !== 'click' && _d.is(':hover');
    _m.toggleClass('show', shouldOpen);
    _d.toggleClass('show', shouldOpen);
    $('[data-bs-toggle="dropdown"]', _d).attr('aria-expanded', shouldOpen);
  }, e.type === 'mouseleave' ? 50 : 0);
}

$('body')
  .on('mouseenter mouseleave','.dropdown',toggleDropdown)
  .on('click', '.dropdown-menu a', toggleDropdown);
</script>


  <script>
    const toggleButton = document.getElementById('toggleTheme');
    toggleButton.addEventListener('click', () => {
      const htmlElement = document.documentElement;
      const currentTheme = htmlElement.getAttribute('data-bs-theme');
      htmlElement.setAttribute('data-bs-theme', currentTheme === 'dark' ? 'light' : 'dark');
    });
  </script>

  <script>
const htmlEl   = document.documentElement;
const themeToggle = document.getElementById("themeToggle");
const themeIcon   = document.getElementById("themeIcon");
const navbar      = document.getElementById("mainNavbar");

function setTheme(theme) {
  // set global theme on <html>
  htmlEl.setAttribute("data-bs-theme", theme);
  localStorage.setItem("theme", theme);

  // set theme on navbar itself
  // navbar.setAttribute("data-bs-theme", theme);

  // flip icon
  themeIcon.className = theme === "light" ? "bi bi-moon-fill" : "bi bi-sun-fill";

  // flip navbar background
  // if (theme === "dark") {
  //   navbar.classList.remove("bg-light");
  //   navbar.classList.add("bg-dark");
  // } else {
  //   navbar.classList.remove("bg-dark");
  //   navbar.classList.add("bg-light");
  // }
}

// Initialize theme (default dark)
const savedTheme = localStorage.getItem("theme");
if (savedTheme) {
  setTheme(savedTheme);
} else {
  setTheme("dark");
}

// Toggle on button click
themeToggle.addEventListener("click", () => {
  const current = htmlEl.getAttribute("data-bs-theme");
  setTheme(current === "light" ? "dark" : "light");
});


</script>


<!--  Trying out animation for dropdown -->

<br><br>

</body>

</html>