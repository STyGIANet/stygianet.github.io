###########################################################################################################

# CONFERENCE AND WORKSHOPS

###########################################################################################################


@inproceedings{pyrrha25,
  author = {Kexin Liu and Zhaochen Zhang and Chang Liu and Yizhi Wang and Vamsi Addanki and Stefan Schmid and Qingyue Wang and Wei Chen and Xiaoliang Wang and Jiaqi Zheng and Wenhao Sun and Tao Wu and Ke Meng and Fei Chen and Weiguang Wang and Bingyang Liu and Wanchun Dou and Guihai Chen and Chen Tian},
  group={conference_workshop},
  tag={NSDI '25},
  paper       = {/papers/pyrrha-nsdi2025.pdf},
  title     = {Pyrrha: Congestion-Root-Based Flow Control to Eliminate Head-of-Line Blocking in Datacenter},
  booktitle = {22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25)},
  year = {2025},
  month = {April},
  address = {Philadelphia, PA},
  location = {Philadelphia, PA},
  publisher = {USENIX Association},
  abstract = {
  In modern datacenters, the effectiveness of end-to-end congestion control (CC) is quickly diminishing with the rapid bandwidth evolution. Per-hop flow control (FC) can react to congestion more promptly. However, a coarse-grained FC can result in Head-Of-Line (HOL) blocking. A fine-grained, per-flow FC can eliminate HOL blocking caused by flow control, however, it does not scale well. This paper presents Pyrrha, a scalable flow control approach that provably eliminates HOL blocking while using a minimum number of queues. In Pyrrha, flow control first takes effect on the root of the congestion, i.e., the port where congestion occurs. And then flows are controlled according to their contributed congestion roots. A prototype of Pyrrha is implemented on Tofino2 switches. Compared with state-of-the-art approaches, the average FCT of uncongested flows is reduced by 42%-98%, and 99th-tail latency can be 1.6×-215× lower, without compromising the performance of congested flows.
  },
}

@inproceedings{cbmconextsw24,
group={poster},
tag = {CoNEXT-SW '24},
paper={/papers/cbm-conextSW2024.pdf},
author = {Agarwal, Krishna and Addanki, Vamsi and Mostafaei, Habib},
title = {Dequeue Rate-Agnostic Switch Buffer Sharing through Packet Queueing Delay},
month={December},
year = {2024},
isbn = {979-8-4007-1255-5/24/1},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694812.3699924},
doi = {10.1145/3694812.3699924},
abstract = {Datacenter network switches share packet buffers among all ports
to enhance throughput and reduce packet drops. However, declining
buffer space per-port-per-bandwidth unit challenges buffer-sharing
mechanisms, affecting performance. Recent studies, like ABM (SIGCOMM 2022), suggest hierarchical packet admission schemes to address this, but their complexity hinders efficiency. We propose CBM, a packet delay-based buffer sharing scheme that manages buffer space and controls queue drain rates using a single configurable parameter. Preliminary evaluation shows that CBM improves advanced transport protocol performance, such as PowerTCP, reducing Flow Completion Times (FCTs) by up to 45.07% compared with ABM.},
booktitle = {Proceedings of the CoNEXT Student Workshop 2024 (CoNEXT-SW ’24)},
numpages = {2},
keywords = {Switch buffer, packet queueing delay, datacenter networks},
location = {Los Angeles, CA, USA},
series = {CoNEXT-SW '24}
}


@inproceedings{starlinkleonet24,
  author = { Hammer, Sarah-Michelle and Addanki, Vamsi and Franke, Max and Schmid, Stefan},
  group={conference_workshop},
  tag={LEO-NET '24},
  paper       = {/papers/starlink-leonet2024.pdf},
  title     = {Starlink Performance through the Edge Router Lens},
  booktitle = {Proceedings of the 2nd ACM Workshop on LEO Networking and Communication 2024},
  year = {2024},
  month = {November},
  address = {Washington, DC., USA},
  location = {Washington, DC., USA},
  abstract = {
  Low-Earth Orbit satellite-based Internet has become commercially available to end users, with Starlink being the most prominent provider. Starlink has been shown to exhibit a periodic pattern with a characteristic throughput drop on the boundaries of 15s intervals, in addition to multiple bands of latency within each 15s interval. A multitude of prior works hypothesize various root causes for this pattern, such as reordering and packet loss. Some works have attributed these effects to the edge router, advocating for explicit feedback to the transport layer. However, with the edge router being a proprietary Starlink device, it raises questions about the extent of its influence on periodic throughput drops, losses, and jitter, leaving us to wonder if we fully understand the underlying issues.
  
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  
  This paper presents the first measurement study with a vantage point that is by far the closest (last hop) to the core Starlink network. We use a Generation 1 dish, which allows us to bypass the proprietary Starlink router and connect a Linux server directly to the dish. We investigate the impact of the edge router on the observed periodic pattern in Starlink performance. Our results are primarily negative in terms of any significant buffer buildup and packet losses at the edge router, suggesting that the causality of the observed patterns lies entirely in the core network, a proprietary space that cannot be fixed by the end user. Interestingly, we observe similar patterns even with a constant bitrate UDP sender, likely indicating that the periodic drop in throughput is not an inherent limitation of existing TCP implementations but rather the core network characteristic!
  },
}


@inproceedings{credencensdi24,
  author = {Addanki, Vamsi and Pacut, Maciej and Schmid, Stefan},
  group={conference_workshop},
  tag={NSDI '24},
  paper       = {/papers/credence-nsdi2024.pdf},
  slides    = {/slides/credence-slides-nsdi2024.pdf},
  code={https://github.com/inet-tub/ns3-datacenter},
  video={https://www.youtube.com/watch?v=sAPe78RFsz0},
  title     = {Credence: Augmenting Datacenter Switch Buffer Sharing with ML Predictions},
  booktitle = {21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)},
  year = {2024},
  month = {April},
  address = {Santa Clara, CA},
  location = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/nsdi24/presentation/addanki-credence},
  publisher = {USENIX Association},
  abstract = {Packet buffers in datacenter switches are shared across all the switch ports in order to improve the overall throughput. The trend of shrinking buffer sizes in datacenter switches makes buffer sharing extremely challenging and a critical performance issue. Literature suggests that push-out buffer sharing algorithms have significantly better performance guarantees compared to drop-tail algorithms. Unfortunately, switches are unable to benefit from these algorithms due to lack of support for push-out operations in hardware. Our key observation is that drop-tail buffers can emulate push-out buffers if the future packet arrivals are known ahead of time. Recent advancements in traffic predictions pave us a way towards better buffer sharing algorithms that leverage predictions.
  
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  
  This paper is the first research attempt in this direction. We propose Credence, a drop-tail buffer sharing algorithm augmented with machine-learned predictions. Credence can unlock the performance only attainable by push-out algorithms so far. Its performance hinges on the accuracy of predictions. Specifically, Credence achieves near-optimal performance of the best known push-out algorithm LQD (Longest Queue Drop) with perfect predictions, but gracefully degrades to the performance of the simplest drop-tail algorithm Complete Sharing when the prediction error gets arbitrarily worse. Our evaluations show that Credence improves throughput by 1.5x compared to traditional approaches. In terms of flow completion times, we show that Credence improves upon the state-of-the-art approaches by up to 95% using off-the-shelf machine learning techniques that are also practical in today's hardware. We believe this work opens several interesting future work opportunities both in systems and theory that we discuss at the end of this paper.},
}


@inproceedings{reveriensdi24,
  author = {Addanki, Vamsi and Bai, Wei and Schmid, Stefan and Apostolaki, Maria},
  group={conference_workshop},
  tag={NSDI '24},
  paper       = {/papers/reverie-nsdi2024.pdf},
  slides    = {/slides/reverie-slides-nsdi2024.pdf},
  code={https://github.com/inet-tub/ns3-datacenter},
  video={https://www.youtube.com/watch?v=_zUOrdqMAcY},
  title     = {Reverie: Low Pass Filter-Based Switch Buffer Sharing for Datacenters with RDMA and TCP Traffic},
  booktitle = {21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)},
  year = {2024},
  month = {April},
  address = {Santa Clara, CA},
  location = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/nsdi24/presentation/addanki-reverie},
  publisher = {USENIX Association},
  abstract = {The switch buffers in datacenters today are shared by traffic classes with different loss tolerance and reaction to congestion signals. In particular, while legacy applications use loss-tolerant transport, e.g., DCTCP, newer applications require lossless datacenter transport, e.g., RDMA over Converged Ethernet. The allocation of buffers for this diverse traffic mix is managed by a buffer-sharing scheme. Unfortunately, as we analytically show in this paper, the buffer-sharing practices of today's datacenters pose a fundamental limitation to effectively isolate RDMA and TCP while also maximizing burst absorption. We identify two root causes: (i) the buffer-sharing for RDMA and TCP relies on two independent and often conflicting views of the buffer, namely ingress and egress; and (ii) the buffer-sharing scheme micromanages the buffer and overreacts to the changes in its occupancy during transient congestion.
  
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  
  In this paper, we present Reverie, a buffer-sharing scheme, which, unlike prior works, is suitable for both lossless and loss-tolerant traffic classes, providing isolation as well as superior burst absorption. At the core of Reverie lies a unified (consolidated ingress and egress) admission control that jointly optimizes the buffers for both traffic classes. Reverie, allocates buffer based on a low-pass filter that naturally absorbs bursty queue lengths during transient congestion within the buffer limits. Our evaluation shows that Reverie can improve the performance of RDMA as well as TCP in terms of flow completion times by up to 33%.},
}



@inproceedings{ebpf23,
  author = {Hinz, J\"{o}rn-Thorben and Addanki, Vamsi and Gy\"{o}rgyi, Csaba and Jepsen, Theo and Schmid, Stefan},
  group={conference_workshop},
  tag={eBPF '23},
  paper       = {/papers/tcpthirdeye-ebpf2023.pdf},
  slides    = {/slides/tcpthirdeye-slides-ebpf2023.pdf},
  code      = {https://github.com/inet-tub/powertcp-linux},
  title     = {TCP's Third-Eye: Leveraging eBPF for Telemetry-Powered Congestion Control},
  year = {2023},
  month = {September},
  booktitle = {Proceedings of the 1st Workshop on eBPF and Kernel Extensions, ACM SIGCOMM 2023 Conference},
  location = {New York, USA},
  abstract  = {
For years, congestion control algorithms have been navigating in the dark, blind to the actual state of the network. They were limited to the course-grained signals that are visible from the OS kernel, which are measured locally (e.g., RTT) or hints of imminent congestion (e.g., packet loss and ECN). As applications and OSs are becoming ever more distributed, it is only natural that the kernel have visibility beyond the host, into the network fabric. Network switches already collect telemetry, but it has been impractical to export it for the end-host to react.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
Although some telemetry-based solutions have been proposed, they require changes to the end-host, like custom hardware or new protocols and network stacks. We address the challenges of efficiency and protocol compatibility, showing that it is possible and practical to run telemetry-based congestion control algorithms in the kernel. We design a CCA running in eBPF that can execute different control laws by selecting different types of telemetry. It can be deployed in brownfield environments, without requiring all switches be telemetry-enabled, or kernel recompilation at the end-hosts. When our eBPF program is enabled on hosts without hardware or OS changes, TCP incast workloads experience less queuing (thus lower latency), faster convergence and better fairness.
  }
}


@inproceedings{mars23,
  author = {Addanki, Vamsi and 
            Avin, Chen and 
            Schmid, Stefan},
  group={conference_workshop},
  tag={SIGMETRICS '23},
  paper       = {/papers/mars-sigmetrics2023.pdf},
  slides    = {/slides/mars-slides-sigmetrics2023.pdf},
  title     = {Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable Datacenter Networks},
  year = {2023},
  month = {June},
  booktitle = {Proc. ACM Meas. Anal. Comput. Syst, ACM SIGMETRICS},
  location = {Orlando, Florida, USA},
  year      = {2023},
  url       = {https://doi.org/10.1145/3579312},
  abstract  = {
  The performance of large-scale computing systems often critically depends on high-performance communication networks. Dynamically reconfigurable topologies, e.g., based on optical circuit switches, are emerging as an innovative new technology to deal with the explosive growth of datacenter traffic. Specifically, periodic reconfigurable datacenter networks (RDCNs) such as RotorNet (SIGCOMM 2017), Opera (NSDI 2020) and Sirius (SIGCOMM 2020) have been shown to provide high throughput, by emulating a complete graph through fast periodic circuit switch scheduling.
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  However, to achieve such a high throughput, existing reconfigurable network designs pay a high price: in terms of potentially high delays, but also, as we show as a first contribution in this paper, in terms of the high buffer requirements. In particular, we show that under buffer constraints, emulating the high-throughput complete-graph is infeasible at scale, and we uncover a spectrum of unvisited and attractive alternative RDCNs, which emulate regular graphs of lower node degree.
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  We present Mars, a periodic reconfigurable topology which emulates a d-regular graph with near-optimal throughput. In particular, we systematically analyze how the degree d can be optimized for throughput given the available buffer and delay tolerance of the datacenter. We further show empirically that Mars achieves higher throughput compared to existing systems when buffer sizes are bounded.
  }
}


@inproceedings{salists,
  group={conference_workshop},
  tag = {INFOCOM '23},
  paper={/papers/listaccess-infocom2023.pdf},
  author = {   Addanki, Vamsi  and
               Pacut, Maciej and
               Pourdamghani, Arash and
               R{\'{e}}tv{\'{a}}ri, G{\'{a}}bor and
               Schmid, Stefan and
               Vanerio, Juan
               },
  abstract = {
We introduce self-adjusting partially ordered lists, a generalization of self-adjusting lists where additionally there may be constraints for the relative order of some nodes in the list.
The lists self-adjust to improve performance while serving input sequences exhibiting favorable properties, such as locality of reference, but the constraints must be respected. 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
We design a deterministic adjusting algorithm that operates without any assumptions about the input distribution, without maintaining frequency statistics or timestamps.
Although the partial order limits the effectiveness of self-adjustments, the deterministic algorithm performs closely to optimum (it is 4-competitive).
In addition, we design a family of randomized algorithms with improved competitive ratios, handling also the rearrangement cost scaled by an arbitrary constant d > 1.
Moreover, we observe that different constraints influence the competitiveness of online algorithms, and we shed light on this aspect with a lower bound.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
We investigate the applicability of our lists in the context of network packet classification. Our evaluations show that
our classifier performs similarly to a~static list for low-locality traffic, but significantly outperforms Efficuts (by~factor $7$x), CutSplit ($3.6$x) and the static list (14x) for high locality and small rulesets.
  },
  title = {Self-Adjusting Partially Ordered Lists},
  year = {2023},
  month = {May},
  booktitle = {Proceedings of the IEEE INFOCOM 2023 Conference},
  location = {New York, USA}
}


@inproceedings{abm,
  group={conference_workshop},
  tag = {SIGCOMM '22},
  paper={/papers/abm-sigcomm2022.pdf},
  slides={/slides/abm-slides-sigcomm2022.pdf},
  code={https://github.com/inet-tub/ns3-datacenter},
  video={https://www.youtube.com/watch?v=fYh9pW1eFqc},
  author = {Addanki, Vamsi and Apostolaki, Maria and Ghobadi, Manya and Schmid, Stefan and Vanbever, Laurent},
  abstract = {Today’s network devices share buffer across queues to
avoid drops during transient congestion and absorb bursts. 
As the buffer-per-bandwidth-unit in datacenter decreases,
the need for optimal buffer utilization becomes more pressing. 
Typical devices use a hierarchical packet admission control scheme:
First, a Buffer Management (BM) scheme decides the maximum length per queue at the device level and then an Active Queue Management (AQM) scheme decides which packets will be admitted at the queue level.
Unfortunately, the lack of cooperation between the two control schemes leads to (i) harmful interference across queues, due to the lack of isolation; (ii) increased queueing delay, due to the obliviousness to the per-queue drain time; and (iii) thus unpredictable burst tolerance.
To overcome these limitations, we propose ABM, Active Buffer Management which incorporates insights from both BM and AQM. Concretely, ABM accounts for both total buffer occupancy (typically used by BM) and queue drain time (typically used by AQM). We analytically prove that ABM provides isolation, bounded buffer drain time and achieves predictable burst tolerance without sacrificing throughput. We empirically find that ABM improves the $99$th percentile FCT for short flows by up to 94% compared to the state-of-the-art buffer management. We further show that ABM improves the performance of advanced datacenter transport protocols in terms of FCT by up to 76% compared to DCTCP, TIMELY and PowerTCP under bursty workloads even at moderate load conditions.},
  title = {ABM: Active Buffer Management in Datacenters},
  year = {2022},
  month = {August},
  booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
  location = {Amsterdam, Netherlands}
}


@inproceedings{nsdi22,
  group={conference_workshop},
  tag = {NSDI '22},
  paper={/papers/powertcp-nsdi2022.pdf},
  slides={/slides/powertcp-slides-nsdi2022.pdf},
  video={https://www.youtube.com/watch?v=5K7p3jiDeR8},
  author = {Addanki, Vamsi and Michel, Oliver and Schmid, Stefan},
  title = {{PowerTCP}: Pushing the Performance Limits of Datacenter Networks},
  abstract = {Increasingly stringent throughput and latency requirements in datacenter networks demand fast and accurate congestion control. We observe that the reaction time and accuracy of existing datacenter congestion control schemes are inherently limited. They either rely only on explicit feedback about the network state (e.g., queue lengths in DCTCP) or only on variations of state (e.g., RTT gradient in TIMELY). To overcome these limitations, we propose a novel congestion control algorithm, PowerTCP, which achieves much more fine-grained congestion control by adapting to the bandwidth-window product (henceforth called power). PowerTCP leverages in-band network telemetry to react to changes in the network instantaneously without loss of throughput and while keeping queues short. Due to its fast reaction time, our algorithm is particularly well-suited for dynamic network environments and bursty traffic patterns. We show analytically and empirically that PowerTCP can significantly outperform the state-of-the-art in both traditional datacenter topologies and emerging reconfigurable datacenters where frequent bandwidth changes make congestion control challenging. In traditional datacenter networks, PowerTCP reduces tail flow completion times of short flows by 80% compared to DCQCN and TIMELY, and by 33% compared to HPCC even at 60% network load. In reconfigurable datacenters, PowerTCP achieves 85% circuit utilization without incurring additional latency and cuts tail latency by at least 2x compared to existing approaches.},
  booktitle = {19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  year = {2022},
  address = {Renton, WA},
  location = {Renton, WA},
  url = {https://www.usenix.org/conference/nsdi22/presentation/addanki},
  publisher = {USENIX Association},
  month = {April},
  website={https://powertcp.self-adjusting.net},
  code={https://github.com/inet-tub/ns3-datacenter}
} 

@inproceedings{detnetnetworking20,
  group={conference_workshop},
  tag = {Networking '20},
  paper={/papers/detnet-networking2020.pdf},
  slides={/slides/detnet-networking2020-slides.odp},
  code={https://github.com/vamsiDT/DeNS},
  author={Addanki, Vamsi and Iannone, Luigi},
  booktitle={2020 IFIP Networking Conference (Networking)}, 
  title={Moving a step forward in the quest for Deterministic Networks (DetNet)},
  abstract={Recent years witnessed a fast-growing demand, in the context of industrial use-cases, for the so-called Deterministic Networks (DetNet). IEEE 802.1 TSN architecture provides linklayer services and IETF DetNet provides network-layer services for deterministic and reliable forwarding. In such a context, in the first part of this paper, we tackle the problem of misbehaving flows and propose a novel queuing and scheduling mechanism, based on Push-In-First-Out (PIFO) queues. Differently from the original DetNet/TSN specifications, our solution is able to guarantee performance of priority flows in spite of misbehaving flows. In the second part of this paper, we present our simulator DeNS:DetNet Simulator, based on OMNET++ and NeSTiNG, providing building blocks for link-layer TSN and network-layer DetNet. Existing simulators have important limitations that do not allow simulating the full DetNet/TSN protocol stack. We overcome these limitations, making easy DetNet/TSN evaluations possible. Our simulations clearly show that our solution is able to satisfy constraints of deterministic networks, namely, guarantee zero packet loss and low latency, while at the same time allowing best-effort flows to co-exist. Furthermore, we show how our newly-proposed queuing and scheduling solution successfully limits the impact of misbehaving flows.},
  month={June},
  year={2020},
  location = {Paris, France},
  volume={},
  number={},
  pages={458-466},
  doi={}}


@inproceedings{aliaspam20,
group={conference_workshop},
tag = {PAM '20},
paper={https://arxiv.org/pdf/2002.00252.pdf},
author="Vermeulen, Kevin
and Ljuma, Burim
and Addanki, Vamsi
and Gouel, Matthieu
and Fourmaux, Olivier
and Friedman, Timur
and Rejaie, Reza",
editor="Sperotto, Anna
and Dainotti, Alberto
and Stiller, Burkhard",
title="Alias Resolution Based on ICMP Rate Limiting",
booktitle="Passive and Active Measurement",
month={March},
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="231--248",
abstract="Alias resolution techniques (e.g., Midar) associate, mostly through active measurement, a set of IP addresses as belonging to a common router. These techniques rely on distinct router features that can serve as a signature. Their applicability is affected by router support of the features and the robustness of the signature. This paper presents a new alias resolution tool called Limited Ltd. that exploits ICMP rate limiting, a feature that is increasingly supported by modern routers that has not previously been used for alias resolution. It sends ICMP probes toward target interfaces in order to trigger rate limiting, extracting features from the probe reply loss traces. It uses a machine learning classifier to designate pairs of interfaces as aliases. We describe the details of the algorithm used by Limited Ltd. and illustrate its feasibility and accuracy. Limited Ltd. not only is the first tool that can perform alias resolution on IPv6 routers that do not generate monotonically increasing fragmentation IDs (e.g., Juniper routers) but it also complements the state-of-the-art techniques for IPv4 alias resolution. All of our code and the collected dataset are publicly available.",
isbn="978-3-030-44081-7"
}



@inproceedings{fairdropsigcomm18,
group={poster},
tag = {SIGCOMM '18},
paper={/papers/fairdrop-demo-sigcomm2018.pdf},
poster={/posters/fairdrop-poster-sigcomm2018.pdf},
video={/videos/fairdrop-bw-demo.mp4},
videocontd={/videos/fairdrop-cpu-demo.mp4},
author = {Addanki, Vamsi and Linguaglossa, Leonardo and Roberts, James and Rossi, Dario},
title = {Fair Dropping for Multi-Resource Fairness in Software Routers Extended Abstract},
month={August},
year = {2018},
isbn = {9781450359153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234200.3234210},
doi = {10.1145/3234200.3234210},
abstract = {We demonstrate that fair dropping is an effective means to realize fair sharing of
bandwidth and CPU in a software router. Analysis underpinning the effectiveness of
the proposed approach is presented elsewhere [1].},
booktitle = {Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos},
pages = {132–134},
numpages = {3},
keywords = {vector packet processing (VPP), fair dropping, multi-resource fairness, Linux Foundation FD.io project},
location = {Budapest, Hungary},
series = {SIGCOMM '18}
}

@inproceedings{fairdropnetworking18,
  group={conference_workshop},
  tag = {Networking '18},
  paper={/papers/fairdrop-networking2018.pdf},
  code={https://github.com/vamsiDT/fairdrop-results},
  author={Addanki, Vamsi and Linguaglossa, Leonardo and Roberts, James and Rossi, Dario},
  booktitle={IFIP Networking Conference (IFIP Networking) and Workshops}, 
  title={Controlling software router resource sharing by fair packet dropping},
  abstract={The paper discusses resource sharing in a software router where both bandwidth and CPU may be bottlenecks. We propose a novel fair dropping algorithm to realize per-flow max-min fair sharing of these resources. The algorithm is compatible with features like batch I/O and batch processing that tend to make classical scheduling impractical. We describe an implementation using Vector Packet Processing, part of the Linux Foundation FD.io project. Preliminary experimental results prove the efficiency of the algorithm in controlling bandwidth and CPU sharing at high speed. Performance in dynamic traffic is evaluated using analysis and simulation, demonstrating that the proposed approach is both effective and scalable.},
  month={May},
  year={2018},
  location = {Zurich, Switzerland},
  volume={},
  number={},
  pages={1-9},
  doi={10.23919/IFIPNetworking.2018.8696549}}


###########################################################################################################

# TECH REPORTS AND ARXIV

###########################################################################################################

@article{ethereal24,
  author    = {Addanki, Vamsi and
               Goyal, Prateesh and
               Marinos, Ilias and Schmid, Stefan},
  status = {arxiv},
  group={techreport_arxiv},
  paper       = {https://arxiv.org/pdf/2407.00550},
  url       = {https://arxiv.org/abs/2407.00550},
  title     = {Ethereal: Divide and Conquer Network Load Balancing in Large-Scale Distributed Training},
  journal   = {CoRR},
  volume    = {abs/2407.00550},
  year      = {2025},
  month     = {February},
  eprinttype = {arXiv},
  eprint    = {2407.00550},
  abstract  = {
  Large-scale distributed training in production datacenters constitutes a challenging workload bottlenecked by network communication. In response, both major industry players (e.g., Ultra Ethernet Consortium) and parts of academia have surprisingly, and almost unanimously, agreed that packet spraying is \emph{necessary} to improve the performance of large-scale distributed training workloads.
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  In this paper, we challenge this prevailing belief and pose the question: \emph{How close can singlepath transport come to matching the performance of packet spraying?} We demonstrate that singlepath transport (from a NIC's perspective) is sufficient and can perform nearly as well as ideal packet spraying, particularly in the context of distributed training in CLOS-based topologies. Our assertion is based on four key observations about workloads driven by collective communication patterns: \emph{(i)} flow sizes are known upon arrival, \emph{(ii)} flow sizes are equal within each step of a collective, \emph{(iii)} the completion time of a collective is more critical than individual flow completion times, and \emph{(iv)} flows can be \emph{split} upon arrival to control load balancing directly from the application layer.  
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  We present Ethereal, a simple distributed load balancing algorithm that opportunistically splits flows and assigns paths to each flow in a transparent manner, requiring little to no changes to existing RDMA NICs. Our evaluation, spanning a wide range of collective communication algorithms and GPT models using Astra-Sim, shows that Ethereal significantly reduces the completion times by up to 30% compared to packet spraying and by up to 40% compared to REPS, even under link failures. This paper offers an alternative perspective for developing next-generation transport protocols tailored to large-scale distributed training.
  }
}



@article{demandawarethroughput24,
  author    = {Addanki, Vamsi and
               Avin, Chen  and
               Schmid, Stefan},
  status = {arxiv},
  group={techreport_arxiv},
  paper       = {https://arxiv.org/pdf/2405.20869},
  url       = {https://arxiv.org/abs/2405.20869},
  title     = {Understanding the Throughput Bounds of Reconfigurable Datacenter Networks},
  journal   = {CoRR},
  volume    = {abs/2405.20869},
  year      = {2024},
  month     = {June},
  eprinttype = {arXiv},
  eprint    = {2405.20869},
  abstract  = {
  The increasing gap between the growth of datacenter traffic volume and the capacity of electrical switches led to the emergence of reconfigurable datacenter network designs based on optical circuit switching. A multitude of research works, ranging from demand-oblivious (e.g., RotorNet, Sirius) to demand-aware (e.g., Helios, ProjecToR) reconfigurable networks, demonstrate significant performance benefits. Unfortunately, little is formally known about the achievable throughput of such networks. Only recently have the throughput bounds of demand-oblivious networks been studied. In this paper, we tackle a fundamental question: Whether and to what extent can demand-aware reconfigurable networks improve the throughput of datacenters?
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;
  This paper attempts to understand the landscape of the throughput bounds of reconfigurable datacenter networks. Given the rise of machine learning workloads and collective communication in modern datacenters, we specifically focus on their typical communication patterns, namely uniform-residual demand matrices. We formally establish a separation bound of demand-aware networks over demand-oblivious networks, proving analytically that the former can provide at least 16% higher throughput. Our analysis further uncovers new design opportunities based on periodic, fixed-duration reconfigurations that can harness the throughput benefits of demand-aware networks while inheriting the simplicity and low reconfiguration overheads of demand-oblivious networks. Finally, our evaluations corroborate the theoretical results of this paper, demonstrating that demand-aware networks significantly outperform oblivious networks in terms of throughput. This work barely scratches the surface and unveils several intriguing open questions, which we discuss at the end of this paper.
  }
}

@article{bufferfbreview21,
  author    = {Maria Apostolaki and
               Vamsi Addanki and
               Manya Ghobadi and
               Laurent Vanbever},
  status = {arxiv},
  group={techreport_arxiv},
  paper       = {https://arxiv.org/pdf/2105.10553.pdf},
  url       = {https://arxiv.org/abs/2105.10553},
  title     = {{FB:} {A} Flexible Buffer Management Scheme for Data Center Switches},
  journal   = {CoRR},
  volume    = {abs/2105.10553},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2105.10553},
  abstract  = {
  Today, network devices share buffer across priority queues to avoid drops during transient congestion. While cost-effective most of the time, this sharing can cause undesired interference among seemingly independent traffic. As a result, low-priority traffic can cause increased packet loss to high-priority traffic. Similarly, long flows can prevent the buffer from absorbing incoming bursts even if they do not share the same queue. The cause of this perhaps unintuitive outcome is that today's buffer sharing techniques are unable to guarantee isolation across (priority) queues without statically allocating buffer space. To address this issue, we designed FB, a novel buffer sharing scheme that offers strict isolation guarantees to high-priority traffic without sacrificing link utilizations. Thus, FB outperforms conventional buffer sharing algorithms in absorbing bursts while achieving on-par throughput. We show that FB is practical and runs at line-rate on existing hardware (Barefoot Tofino). Significantly, FB's operations can be approximated in non-programmable devices.
  }
}

@article{firewallreview21,
  author    = {Maciej Pacut and
               Juan Vanerio and
               Vamsi Addanki and
               Arash Pourdamghani and
               G{\'{a}}bor R{\'{e}}tv{\'{a}}ri and
               Stefan Schmid},
  title     = {Self-Adjusting Packet Classification},
  group={techreport_arxiv},
  status={arxiv},
  paper={https://arxiv.org/pdf/2109.15090.pdf},
  journal   = {CoRR},
  volume    = {abs/2109.15090},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.15090},
  eprinttype = {arXiv},
  eprint    = {2109.15090},
  abstract = {
This paper is motivated by the vision of more efficient packet classification mechanisms that self-optimize in a demand-aware manner. At the heart of our approach lies a self-adjusting linear list data structure, where unlike in the classic data structure, there are dependencies, and some items must be in front of the others; for example, to correctly classify packets by rules arranged in a linked list, each rule must be in front of lower priority rules that overlap with it. After each access we can rearrange the list, similarly to Move-To-Front, but dependencies need to be respected.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
We present a 4-competitive online rearrangement algorithm, whose cost is at most four times worse than the optimal offline algorithm; no deterministic algorithm can be better than 3-competitive. The algorithm is simple and attractive, especially for memory-limited systems, as it does not require any additional memory (e.g., neither timestamps nor frequency statistics). Our approach can simply be deployed as a drop-in replacement for a static datastructure, potentially benefitting many existing networks.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
We evaluate our self-adjusting list packet classifier on realistic ruleset and traffic instances. We find that our classifier performs similarly to a static list for low-locality traffic, but significantly outperforms Efficuts (by a factor 7x), CutSplit (3.6x), and the static list (14x) for high locality and small rulesets. Memory consumption is 10x lower on average compared to Efficuts and CutSplit.
  }
}

@article{listaccessreview21,
  author    = {Maciej Pacut and
               Juan Vanerio and
               Vamsi Addanki and
               Arash Pourdamghani and
               G{\'{a}}bor R{\'{e}}tv{\'{a}}ri and
               Stefan Schmid},
  group={techreport_arxiv},
  status={arxiv},
  paper={https://arxiv.org/pdf/2104.08949.pdf},
  title     = {Online List Access with Precedence Constraints},
  journal   = {CoRR},
  volume    = {abs/2104.08949},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.08949},
  eprinttype = {arXiv},
  eprint    = {2104.08949},
  abstract = {
  This paper considers a natural generalization of the online list access problem in the paid exchange model, where additionally there can be precedence constraints ("dependencies") among the nodes in the list. For example, this generalization is motivated by applications in the context of packet classification. Our main contributions are constant-competitive deterministic and randomized online algorithms, designed around a procedure Move-Recursively-Forward, a generalization of Move-To-Front tailored to handle node dependencies. Parts of the analysis build upon ideas of the classic online algorithms Move-To-Front and BIT, and address the challenges of the extended model. We further discuss the challenges related to insertions and deletions.
  }
}


###########################################################################################################

# THESES

###########################################################################################################

  @dissertation{vamsiphdthesis,
    group={thesis},
    thesis={PhD Thesis},
    paper={/papers/vamsi-phd-thesis2025.pdf},
    advisor={Stefan Schmid},
    committee={Axel Küpper, Stefan Schmid, Rachit Agarwal, Michael Schapira, Anja Feldmann, Maria Apostolaki},
    location={TU Berlin},
    title={Adaptive Protocols and Reconfigurable Optical Interconnects for Datacenter Networks},
    author={Vamsi Addanki},
    abstract={Datacenter networks form the backbone of modern computing and storage, driving
    the expansion of online services and applications. As these networks evolve,
    the demand for higher bandwidth and lower latency has increased significantly.
    Recently, GPU clusters have emerged within datacenters for large-scale distributed
    training, presenting unique networking challenges.
    <br>
    &nbsp;&nbsp;&nbsp;&nbsp;
    This thesis addresses several critical challenges in datacenter networks—congestion
    control, load balancing, buffer sharing, and reconfigurable optical interconnects—and
    is structured into three main parts.
    <br>
    &nbsp;&nbsp;&nbsp;&nbsp;
    First, we address the transport protocol problem in modern datacenters. We
    propose PowerTCP, a novel congestion control algorithm that dynamically adjusts
    the congestion window based on the bandwidth-window product (or “power”),
    a new congestion indicator. Through both analytical and empirical validation,
    we demonstrate PowerTCP’s practicality in datacenter networks, showing that it
    meets key requirements for high throughput and low latency. We further introduce
    Ethereal, a transport protocol specifically designed for distributed training work-
    loads in leaf-spine topologies. Ethereal achieves optimal load balancing, akin to
    packet spraying, by minimally splitting a few application flows while maintaining
    single-path transport semantics from the network’s perspective. Empirically, we
    show that Ethereal surpasses state-of-the-art algorithms in collective communica-
    tion completion times.
    <br>
    &nbsp;&nbsp;&nbsp;&nbsp;
    Second, we tackle the buffer-sharing problem in datacenter switches. We
    propose ABM, an innovative buffer-sharing algorithm that ensures isolation across
    different traffic classes while improving burst absorption. As an extension, we
    introduce Reverie, a solution that enables lossy and lossless traffic to coexist within
    the same network. Reverie preserves isolation between these traffic types while
    enhancing burst absorption and flow completion times for both. Additionally, we
    propose Credence, the first buffer-sharing algorithm to integrate machine-learned
    predictions. Our analysis shows that Credence achieves near-optimal throughput
    under perfect predictions and performs effectively even with imperfect predictions,
    significantly improving flow completion times in empirical tests.
    <br>
    &nbsp;&nbsp;&nbsp;&nbsp;
    Finally, as Moore’s law approaches its limits, we address the challenge of high-
    performance optical interconnects in datacenter networks. We present the first
    formal result on the throughput of periodic networks, establishing an equivalence
    to a corresponding static network. Based on this result, we propose Mars, a
    demand-oblivious reconfigurable optical interconnect that achieves near-optimal
    throughput and low latency across various traffic patterns, even with shallow buffers.
    Additionally, we introduce Vermilion, a demand-aware optical interconnect that
    dynamically reconfigures according to traffic patterns. Our analysis and empirical
    results show that Vermilion delivers high throughput across diverse traffic patterns,
    exceeding the throughput capabilities of demand-oblivious interconnects.},
    month={December},
    year={2024}
  }

  @thesis{masterthesis,
  group={thesis},
  thesis={Masters Thesis},
  paper={/papers/vamsi-msc-thesis2020.pdf},
  slides={/slides/vamsi-msc-thesis2020-slides.odp},
  supervisors={Laurent Vanbever, Maria Apostalaki, Sebastien Tixeuil},
  location={ETH Zurich},
  title={Plasticine: A flexible buffer management scheme for data center networks},
  author={Vamsi Addanki},
  abstract={Network devices today share buffer across output queues to avoid drops during transient congestion with less buffer space, thus with a lower cost, per chip. While effective most of the time, this sharing can cause undesired interactions among seemingly independent traffic, especially in case of high load. As a result, low-priority traffic can cause increased packet loss to high-priority traffic, intra-DC traffic can impair WAN throughput and long flows can prevent the buffer for absorbing incoming bursts.
  The cause of this perhaps unintuitive outcome is today's buffer sharing techniques that are unable to guarantee isolation even to a small portion of the traffic, without statically allocating buffer space.
  To address this issue we designed Plasticine a novel buffer management scheme which offers strict isolation guarantees without keeping the buffer idle and is practical in today's hardware.
  We found that Plasticine: \emph{(i)} significantly improves query completion times ($\approx >30\%$ compared to state-of-the-art solution) while achieving on-par throughput compared to convectional buffer management algorithms as well as TCP nuances; \emph{(ii)} improves short-flow completion times; Our proposal is the first attempt to address the problems of bursts in today's data center networks from a buffer management perspective.},
  month={August},
  year={2020}
}

@thesis{bachelorthesis,
  group={thesis},
  thesis={Bachelors Thesis},
  paper={/papers/vamsi-be-thesis2017.pdf},
  supervisors={Dario Rossi, Leonardo Linguaglossa},
  location={Telecom Paris},
  title={Vectorized Packet Processing},
  author={Vamsi Addanki},
  abstract={In the last few years, numerous frameworks have emerged which implement network
  packet processing in user-space using kernel bypass techniques, high-speed software
  data plane functionalities on commodity hardware. VPP [3] is one such framework
  which gained popularity recently for some of the interesting points like its flexibility,
  user-space implementation, kernel bypass techniques etc. VPP allows users to arrange or
  rearrange the network functions as a packet processing graph, providing a Full-blown
  stack of network functions. Unlike the other frameworks in which packet processing is
  done packet-by-packet, VPP performs packet processing, vector-by-vector i.e a batch of
  packets at once. This brings a significant performance benefits due to L1 cache hit.
  In this report I discuss an introduction to Vector Packet Processor, a framework by Cisco
  which is now a part of the Fast Data Input Output (FD.io) project [2]. Later in this report
  I will discuss about the initial experiments on VPP, the test bed used for performing the
  experiments with VPP and how to set up the test bed. The variation of three values
  (Throughput, Average Vector size, CPU clock cycles) are observed while changing
  Maximum vector size. The result clearly show that cache-hit ratio increases from vector
  size of 4 to 256 where it is maximum and decreases.I begin with related work about
  packet processing to understand why VPP is important in the high speed networking
  world.},
  month={July},
  year={2017}
}